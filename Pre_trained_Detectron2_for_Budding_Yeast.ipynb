{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Detectron2 for detecting budding spots in yeast\n",
        "Follow these steps to use a pre-trained model of Detectron2 on yeast data to detect budding spots in your microscopy images.\n",
        "## Step 1: Setup your Google Drive\n",
        "- Create a folder called Detectron2_budding_yeast in the root of your Google Drive\n",
        "- Upload this ipynb file in the folder\n",
        "- Upload the model model_final.pth in a folder model\n",
        "- Upload your tif files in a folder new_data_tif\n",
        "\n",
        "## Step 2: Open this file from Google Drive using Google Colaboratory and mount Drive by running the cell below\n",
        "- Install Google Colaboratory using Google Workspace Marketplace and link to Google Drive if neccesary\n",
        "- Accept the access request from Google Colaboratory for Google Drive prompted when running the code cell below\n",
        "\n"
      ],
      "metadata": {
        "id": "ssOQb4J1RfTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Detectron2_budding_yeast"
      ],
      "metadata": {
        "id": "nIkpsdhDArg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Install Detectron2 and setup by running the three code cells below\n",
        "- Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "- See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions"
      ],
      "metadata": {
        "id": "K2DDaVEmVtbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3G6nn-iAgRT"
      },
      "outputs": [],
      "source": [
        "import sys, os, distutils.core\n",
        "\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "uVBTigKyDaey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "# import tif library\n",
        "import tifffile as tiff\n"
      ],
      "metadata": {
        "id": "pd_YcY5sDfZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Inference with config parameters"
      ],
      "metadata": {
        "id": "gkegBPtzzdAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # learning rate\n",
        "cfg.SOLVER.MAX_ITER = 500    # run for 500 iterations\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # confidence required to label a budding spot\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "ch9JTAOeIxQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Visualize performance on new data"
      ],
      "metadata": {
        "id": "KcsAVZtFznpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = 'output_masks/'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "tif_file_path = 'new_data_tif/'\n",
        "tif_files = [os.path.join(tif_file_path, img_name) for img_name in os.listdir(tif_file_path)]\n",
        "\n",
        "# Create a dictionary to store the masks for each cell\n",
        "cell_masks = {}\n",
        "\n",
        "for cell, tif_file in enumerate(tif_files):\n",
        "    # Load the 4D TIFF image\n",
        "    img = tiff.imread(tif_file)\n",
        "\n",
        "    # Initialize an empty list to store masks for each cell\n",
        "    cell_masks[cell] = []\n",
        "\n",
        "    # Get the shape of the first mask to ensure all masks have the same shape\n",
        "    mask_shape = None\n",
        "\n",
        "    # Iterate through the time (t) and z-stacks\n",
        "    for t in range(img.shape[0]):\n",
        "        cell_masks[cell].append([])\n",
        "        for z in range(img.shape[1]):\n",
        "            # Extract the frame for the current time (t) and z-stack\n",
        "            page = img[t, z, :, :]\n",
        "\n",
        "            # Normalize pixel values to the range [0, 255]\n",
        "            image = cv2.normalize(page, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "            # Convert the frame to BGR\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # Annotate the data\n",
        "            outputs = predictor(image)\n",
        "            masks = outputs[\"instances\"].pred_masks.cpu().numpy()\n",
        "\n",
        "            # Initialize an empty mask array with the same shape as the image\n",
        "            union_mask = np.zeros_like(image[:,:,0])\n",
        "\n",
        "            # Iterate through each mask and update the union_mask\n",
        "            for mask in masks:\n",
        "                union_mask = np.logical_or(union_mask, mask)\n",
        "\n",
        "            # Append the union mask to the list of masks for the cell\n",
        "            cell_masks[cell][t].append(cv2.normalize(union_mask.astype(np.uint8), None, 0, 255, cv2.NORM_MINMAX))\n",
        "\n",
        "            # Update mask shape if not initialized yet\n",
        "            if mask_shape is None:\n",
        "                mask_shape = union_mask.shape\n",
        "\n",
        "    # Check if mask shape is initialized\n",
        "    if mask_shape is not None:\n",
        "        # Convert masks to numpy array and check for any discrepancies in shape\n",
        "        stacked_masks = np.array(cell_masks[cell])\n",
        "        if not all(mask.shape == mask_shape for mask in stacked_masks.flatten()):\n",
        "            print(f\"Warning: Inconsistent mask shapes in cell {cell+1}.\")\n",
        "        # Save the 4D TIFF file for each cell with z layers per t timestep\n",
        "        tiff.imwrite(os.path.join(output_folder, f\"cell{cell+1}_masks.tif\"), stacked_masks)\n",
        "    else:\n",
        "        print(f\"Warning: No masks found for cell {cell+1}.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "by6y4H2TsV5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}